{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3장 딥러닝 기초"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 전결합층 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 공통 클래스 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BaseLayer 클래스를 update 메소드로 구현\n",
    "# 최적화 알고리즘을 구현하기 위해 확률적 경사 하강법(SGD)을 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseLayer:\n",
    "    def update(self, eta):\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.b -= eta * self.grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# self.이 붙어있는 변수는 다른 메소드나 외부와 공유하는 변수\n",
    "# 아다그라드나 아담 등의 최적화 알고리즘을 구현할 때 위 BaseLayer 클래스를 변경해야함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 은닉층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 초기화를 위해 __init__ 메소드, 순전파를 위한 forward 메소드, 역전파를 위한 backward 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleLayer(BaseLayer):\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) * np.sqrt(2/n_upper)\n",
    "        self.b = np.zeros(n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.where(self.u <= 0, 0, self.u)\n",
    "        \n",
    "    def backward(self, grad_y):\n",
    "        delta = grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        self.grad_x = np.dot(delta, self.w.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __init__ 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_upper는 앞 층의 뉴런 수, n은 해당 층의 뉴런 수\n",
    "# 가중치 self.w의 초깃값은 평균이 0이고 표준편타가 루트(2/m)인 He초깃값 사용\n",
    "# m은 앞 층의 뉴런 수\n",
    "# He 초깃값은 활성화 함수가 ReLU일 때, 여러 층을 거쳐도 값에 편향이 생기기 어렵다고 알려짐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### forward 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 활성화 함수로 ReLU함수 사용\n",
    "# ReLU는 forward 메소드 안에 where 함수를 사용해 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta 계산\n",
    "# 우변은 출력 기울기와 활성화 함수를 편미분한 것(편도함수)의 곱으로, 인수인 grad_y가 출력 기울기\n",
    "# ReLU의 편도함수 아래 식과 같음\n",
    "# np.where(self.u <= 0, 0, 1)\n",
    "# grad_y * np.where(self.u <= 0, 0, 1) 의 결과값으로 delta 구하고, 이 값으로 각 기울기 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 출력층 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(BaseLayer):\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)\n",
    "        self.b = np.zeros(n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.exp(u)/np.sum(np.exp(u), axis=1, keepdims=True)\n",
    "        \n",
    "    def backward(self, t):\n",
    "        delta = self.y - t\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        slef.grad_x = np.dot(delta, self.w.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __init__ 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가중치 self.w의 초깃값에 표준편차 값이 (시그마 = 루트(1/m))인 자비에르 초기화 기반의 초깃값을 사용\n",
    "# m은 앞 층의 뉴런 수\n",
    "# 자비에르 초기화 기반의 초깃값은 활성화함수가 좌우대칭일 경우 값의 편차가 커지는 것을 방지해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### forward 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 소프트맥스 함수를 활성화 함수로 이용\n",
    "# 소프트맥스 함수는 함수의 출력값 y는 반드시 0보다 크며 층의 모든 뉴런에서 총합을 구하면 값이 1이므로 확률을 표현하는데 사용됨\n",
    "# sum 함수를 이용해 소프트맥스 함수를 구현하는데, axis=1 로 지정하고 샘플마다 총합을 구하고,\n",
    "# keepdims = True로 지정해 배열의 차원을 유지해줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### backward 메소드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 기울기와 활성화 함수의 편도함수 곱을 이용해 delta 계산\n",
    "# 예제 코드는 다수의 클래스를 분류하는 문제이므로 교차 엔트로피 오차를 오차함수로 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 단순한 딥러닝 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.1 손글씨 숫자 이미지 데이터 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 형태: (1797, 64)\n",
      "레이블: [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "digits_data = datasets.load_digits()\n",
    "\n",
    "n_img = 10  # 출력할 이미지 개수\n",
    "plt.figure(figsize=(10,4))\n",
    "for i in range(n_img):\n",
    "    ax = plt.subplot(2, 5, i+1)\n",
    "    plt.imshow(digits_data.data[i].reshape(8, 8), cmap=\"Greys_r\")\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "print(\"데이터 형태:\", digits_data.data.shape)\n",
    "print(\"레이블:\", digits_data.target[:n_img])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력과 정답 데이터를 표준화하고 원핫 인코딩으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# input_data = np.asarray(digits_data.data)\n",
    "# input_data = (input_data - np.average(input_data)) / np.std(input_data)\n",
    "\n",
    "# correct = np.asarray(digits_data.target)\n",
    "# correct_data = np.zeros((len(correct), n_out))\n",
    "# for i in range(len(correct)):\n",
    "#    correct_data[i, correct[i]] = 1\n",
    "    \n",
    "# x_train, x_test, t_train, t_test = train_test_split(input_data, correct_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.3 순전파와 역전파"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- 각 층의 초기화 --\n",
    "# layers = [MiddleLayer(img_size*img_size, n_mid),\n",
    "#         MiddleLayer(n_mid, n_mid),\n",
    "#         OutputLayer(n_mid, n_out)]\n",
    "\n",
    "# -- 순전파 --\n",
    "# def forward_propagation(x):\n",
    "#    for layer in layers:\n",
    "#        layer.forward(x)\n",
    "#        x = layer.y\n",
    "#    return x\n",
    "\n",
    "# -- 역전파 --\n",
    "# def backwardpropagation(t):\n",
    "#    grad_y = t\n",
    "#    for layer in reversed(layers):\n",
    "#        layer.backward(grad_y)\n",
    "#        grad_y = layer.grad_x\n",
    "#    return grad_y\n",
    "\n",
    "# -- 파라미터 갱신 --\n",
    "# def update_params():\n",
    "#    for layer in layers:\n",
    "#        layer.update(eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.4 미니 배치 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_batch = len(x_train) // batch_size  # 1에포크당 배치 개수\n",
    "# for i in range(epochs):\n",
    "    \n",
    "    # -- 학습 --\n",
    "#    index_random = np.arange(len(x_train))\n",
    "#    np.random.shuffle(index_random)   # 인덱스를 랜덤으로 섞기\n",
    "#    for j in range(n_batch):\n",
    "        \n",
    "        # 미니 배치 구성\n",
    "#        mb_index = index_random[j*batch_size : (j+1)*batch_size]\n",
    "#        x_mb = x_train[mb_index, :]\n",
    "#        t_mb = t_train[mb_index, :]\n",
    "        \n",
    "        # 순전파와 역전파\n",
    "#        forward_propagation(x_mb)\n",
    "#        backwardpropagation(t_mb)\n",
    "        \n",
    "        # 파라미터 갱신\n",
    "#        update_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 손글씨 숫자 이미지 인식의 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1/51 Error_train: 2.623523639024449 Error_test: 2.5749005129959963\n",
      "Epoch:1/51 Error_train: 2.545802253742348 Error_test: 2.505280285333727\n",
      "Epoch:1/51 Error_train: 2.4936987455976634 Error_test: 2.4572610524979175\n",
      "Epoch:1/51 Error_train: 2.444112443085972 Error_test: 2.4084585332186643\n",
      "Epoch:1/51 Error_train: 2.4003413282108967 Error_test: 2.368945242291979\n",
      "Epoch:1/51 Error_train: 2.3650208044385397 Error_test: 2.338509733864131\n",
      "Epoch:1/51 Error_train: 2.338853894037925 Error_test: 2.3161570344096636\n",
      "Epoch:1/51 Error_train: 2.3177975698749713 Error_test: 2.296200749230702\n",
      "Epoch:1/51 Error_train: 2.2958396054157046 Error_test: 2.2790446867098573\n",
      "Epoch:1/51 Error_train: 2.272310793162591 Error_test: 2.257469124234819\n",
      "Epoch:1/51 Error_train: 2.2556204807572726 Error_test: 2.244544908117176\n",
      "Epoch:1/51 Error_train: 2.2436857198665128 Error_test: 2.2328007017565925\n",
      "Epoch:1/51 Error_train: 2.224153607811394 Error_test: 2.2151599883283324\n",
      "Epoch:1/51 Error_train: 2.215732816033696 Error_test: 2.2050953872890786\n",
      "Epoch:1/51 Error_train: 2.205746271061233 Error_test: 2.195132418515377\n",
      "Epoch:1/51 Error_train: 2.193430851947967 Error_test: 2.1873741858105005\n",
      "Epoch:1/51 Error_train: 2.180455655531385 Error_test: 2.172347760571494\n",
      "Epoch:1/51 Error_train: 2.1667169168875575 Error_test: 2.1615604497746594\n",
      "Epoch:1/51 Error_train: 2.1557984220127175 Error_test: 2.1502733274848467\n",
      "Epoch:1/51 Error_train: 2.1454938023426307 Error_test: 2.1408953757629723\n",
      "Epoch:1/51 Error_train: 2.134211499834885 Error_test: 2.132739606863607\n",
      "Epoch:1/51 Error_train: 2.120994428064625 Error_test: 2.120081236724527\n",
      "Epoch:1/51 Error_train: 2.1098366429351105 Error_test: 2.1113132044414584\n",
      "Epoch:1/51 Error_train: 2.09858443006196 Error_test: 2.101374575984987\n",
      "Epoch:1/51 Error_train: 2.084969150227333 Error_test: 2.091152181812566\n",
      "Epoch:1/51 Error_train: 2.0746415424661135 Error_test: 2.0804164246144348\n",
      "Epoch:1/51 Error_train: 2.069148281492412 Error_test: 2.077040060650372\n",
      "Epoch:1/51 Error_train: 2.0572345803010026 Error_test: 2.062861480623945\n",
      "Epoch:1/51 Error_train: 2.0468833217332145 Error_test: 2.053472078560375\n",
      "Epoch:1/51 Error_train: 2.037639346446666 Error_test: 2.047142321059896\n",
      "Epoch:1/51 Error_train: 2.0258839798639405 Error_test: 2.0368725414744944\n",
      "Epoch:1/51 Error_train: 2.0147129380308284 Error_test: 2.0258108021893473\n",
      "Epoch:1/51 Error_train: 2.005559823055963 Error_test: 2.019187913300676\n",
      "Epoch:1/51 Error_train: 1.9963171608116506 Error_test: 2.009216650580297\n",
      "Epoch:1/51 Error_train: 1.988481087096409 Error_test: 2.0004137927461305\n",
      "Epoch:1/51 Error_train: 1.9779965042764385 Error_test: 1.9915468291357905\n",
      "Epoch:1/51 Error_train: 1.9708889049151408 Error_test: 1.9854870524756438\n",
      "Epoch:1/51 Error_train: 1.9629858105697775 Error_test: 1.9787434498047747\n",
      "Epoch:1/51 Error_train: 1.9517834371783793 Error_test: 1.968639410925518\n",
      "Epoch:1/51 Error_train: 1.9406294006053006 Error_test: 1.957709670354346\n",
      "Epoch:1/51 Error_train: 1.9326815315829657 Error_test: 1.9510397108626103\n",
      "Epoch:1/51 Error_train: 1.9240470179865716 Error_test: 1.9405091302007664\n",
      "Epoch:6/51 Error_train: 0.5219350944635949 Error_test: 0.6131661644657883\n",
      "Epoch:6/51 Error_train: 0.5157201934696537 Error_test: 0.6068013118612521\n",
      "Epoch:6/51 Error_train: 0.5162953346186118 Error_test: 0.6055665627601176\n",
      "Epoch:6/51 Error_train: 0.514946296499054 Error_test: 0.6070918725746246\n",
      "Epoch:6/51 Error_train: 0.5068807232396878 Error_test: 0.5982926177932986\n",
      "Epoch:6/51 Error_train: 0.5048445367578148 Error_test: 0.5932011153708405\n",
      "Epoch:6/51 Error_train: 0.5053237354079618 Error_test: 0.5963829407243555\n",
      "Epoch:6/51 Error_train: 0.5010223131339409 Error_test: 0.592026858305928\n",
      "Epoch:6/51 Error_train: 0.4984455389579548 Error_test: 0.5898413495067495\n",
      "Epoch:6/51 Error_train: 0.4906295912986862 Error_test: 0.5857496201335934\n",
      "Epoch:6/51 Error_train: 0.4888920574567774 Error_test: 0.5825907042583214\n",
      "Epoch:6/51 Error_train: 0.4879697083379069 Error_test: 0.5837241335278597\n",
      "Epoch:6/51 Error_train: 0.4845098038050304 Error_test: 0.5772960435521893\n",
      "Epoch:6/51 Error_train: 0.4782424751004468 Error_test: 0.5705097935147467\n",
      "Epoch:6/51 Error_train: 0.4773293411704053 Error_test: 0.5654774321507453\n",
      "Epoch:6/51 Error_train: 0.4736180897657124 Error_test: 0.5622128490214806\n",
      "Epoch:6/51 Error_train: 0.47508930771607716 Error_test: 0.5649807539656193\n",
      "Epoch:6/51 Error_train: 0.4704638538101351 Error_test: 0.5623856773768449\n",
      "Epoch:6/51 Error_train: 0.4654848451475529 Error_test: 0.5617371286636773\n",
      "Epoch:6/51 Error_train: 0.4658386906269086 Error_test: 0.5663100676428281\n",
      "Epoch:6/51 Error_train: 0.4701051967701746 Error_test: 0.5686795816269745\n",
      "Epoch:6/51 Error_train: 0.46801399635347557 Error_test: 0.5728564746981709\n",
      "Epoch:6/51 Error_train: 0.45868149609101166 Error_test: 0.5579002920375075\n",
      "Epoch:6/51 Error_train: 0.4651727697227457 Error_test: 0.558189645777842\n",
      "Epoch:6/51 Error_train: 0.45336558107954134 Error_test: 0.5450445613346057\n",
      "Epoch:6/51 Error_train: 0.4509746900877285 Error_test: 0.5447723221858222\n",
      "Epoch:6/51 Error_train: 0.4466092129534652 Error_test: 0.5415239171164997\n",
      "Epoch:6/51 Error_train: 0.44334379893685394 Error_test: 0.5353285868002625\n",
      "Epoch:6/51 Error_train: 0.43637441108669633 Error_test: 0.5257803116499395\n",
      "Epoch:6/51 Error_train: 0.4344044365876558 Error_test: 0.5234290958867434\n",
      "Epoch:6/51 Error_train: 0.43454389001886506 Error_test: 0.5291284916834657\n",
      "Epoch:6/51 Error_train: 0.43072175385938166 Error_test: 0.5283396278840102\n",
      "Epoch:6/51 Error_train: 0.4255645620817342 Error_test: 0.5204238187540946\n",
      "Epoch:6/51 Error_train: 0.42869576677189114 Error_test: 0.5241953356759784\n",
      "Epoch:6/51 Error_train: 0.42292076445592836 Error_test: 0.5175142401322853\n",
      "Epoch:6/51 Error_train: 0.4201557844580689 Error_test: 0.5180374278583285\n",
      "Epoch:6/51 Error_train: 0.4212299967130234 Error_test: 0.5198268454236407\n",
      "Epoch:6/51 Error_train: 0.41760020288113486 Error_test: 0.5147138373060445\n",
      "Epoch:6/51 Error_train: 0.41132811693878285 Error_test: 0.5078311543346389\n",
      "Epoch:6/51 Error_train: 0.4120291444212504 Error_test: 0.5058512636320858\n",
      "Epoch:6/51 Error_train: 0.40643262925333 Error_test: 0.503655250966443\n",
      "Epoch:6/51 Error_train: 0.4082472264281969 Error_test: 0.5071032953069436\n",
      "Epoch:11/51 Error_train: 0.22346977636081058 Error_test: 0.3129902503780468\n",
      "Epoch:11/51 Error_train: 0.22259318226793035 Error_test: 0.31468968201257747\n",
      "Epoch:11/51 Error_train: 0.2256948687053854 Error_test: 0.3133256861329316\n",
      "Epoch:11/51 Error_train: 0.2277139112743083 Error_test: 0.3158544635011881\n",
      "Epoch:11/51 Error_train: 0.23133314066887384 Error_test: 0.31881916815910927\n",
      "Epoch:11/51 Error_train: 0.23060821512391932 Error_test: 0.31698803666235487\n",
      "Epoch:11/51 Error_train: 0.22616152403632137 Error_test: 0.31284018207532743\n",
      "Epoch:11/51 Error_train: 0.23044963088173667 Error_test: 0.3164216830433035\n",
      "Epoch:11/51 Error_train: 0.2260155935822548 Error_test: 0.3093493324616509\n",
      "Epoch:11/51 Error_train: 0.22202132684001025 Error_test: 0.3075784228785638\n",
      "Epoch:11/51 Error_train: 0.21806820902818788 Error_test: 0.3043250522003775\n",
      "Epoch:11/51 Error_train: 0.21783936040892501 Error_test: 0.3015866025708925\n",
      "Epoch:11/51 Error_train: 0.2174494364627559 Error_test: 0.3013923321923318\n",
      "Epoch:11/51 Error_train: 0.2181932687730819 Error_test: 0.30255564163685933\n",
      "Epoch:11/51 Error_train: 0.21580480366628868 Error_test: 0.3054624023085058\n",
      "Epoch:11/51 Error_train: 0.217376902790901 Error_test: 0.3091456724550316\n",
      "Epoch:11/51 Error_train: 0.21808546031759318 Error_test: 0.30748221838665524\n",
      "Epoch:11/51 Error_train: 0.21670898956092438 Error_test: 0.30976486395117675\n",
      "Epoch:11/51 Error_train: 0.21857130275154 Error_test: 0.3112254411039982\n",
      "Epoch:11/51 Error_train: 0.2147976999179391 Error_test: 0.30758203008022705\n",
      "Epoch:11/51 Error_train: 0.220948278002819 Error_test: 0.3153852906170365\n",
      "Epoch:11/51 Error_train: 0.2147611987769628 Error_test: 0.305818352939951\n",
      "Epoch:11/51 Error_train: 0.21634975119308414 Error_test: 0.3111037269450294\n",
      "Epoch:11/51 Error_train: 0.2153472146501889 Error_test: 0.3089053458551597\n",
      "Epoch:11/51 Error_train: 0.21201867636520683 Error_test: 0.30037424475681845\n",
      "Epoch:11/51 Error_train: 0.21136122823894823 Error_test: 0.30013207442454104\n",
      "Epoch:11/51 Error_train: 0.21209515050470476 Error_test: 0.29933083038735203\n",
      "Epoch:11/51 Error_train: 0.2185878737367085 Error_test: 0.30957462591188323\n",
      "Epoch:11/51 Error_train: 0.21979038188310768 Error_test: 0.30923184042814084\n",
      "Epoch:11/51 Error_train: 0.21817684814311536 Error_test: 0.3065601536742236\n",
      "Epoch:11/51 Error_train: 0.21953122403608913 Error_test: 0.31107348442394833\n",
      "Epoch:11/51 Error_train: 0.2232423562394094 Error_test: 0.32059024484349985\n",
      "Epoch:11/51 Error_train: 0.21472230696329903 Error_test: 0.3064757511592618\n",
      "Epoch:11/51 Error_train: 0.21325402251961703 Error_test: 0.30355742941645364\n",
      "Epoch:11/51 Error_train: 0.20863302608369372 Error_test: 0.29870006682212097\n",
      "Epoch:11/51 Error_train: 0.20777250880206713 Error_test: 0.30020759355528154\n",
      "Epoch:11/51 Error_train: 0.20676074156269397 Error_test: 0.3011999702195659\n",
      "Epoch:11/51 Error_train: 0.2080960116977397 Error_test: 0.3030131878989817\n",
      "Epoch:11/51 Error_train: 0.20317868570932168 Error_test: 0.29754033160620874\n",
      "Epoch:11/51 Error_train: 0.20501768321775973 Error_test: 0.3004502332137995\n",
      "Epoch:11/51 Error_train: 0.20452600560060627 Error_test: 0.295623012530717\n",
      "Epoch:11/51 Error_train: 0.2101533285289256 Error_test: 0.2988618716474747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:16/51 Error_train: 0.15613261501339926 Error_test: 0.24445509746713606\n",
      "Epoch:16/51 Error_train: 0.14586876743923916 Error_test: 0.23389775913471383\n",
      "Epoch:16/51 Error_train: 0.1447437413921645 Error_test: 0.23368492773270627\n",
      "Epoch:16/51 Error_train: 0.14235945788572807 Error_test: 0.23544350976790646\n",
      "Epoch:16/51 Error_train: 0.14511630376859194 Error_test: 0.23222024589046086\n",
      "Epoch:16/51 Error_train: 0.14445932506435374 Error_test: 0.23457458057689\n",
      "Epoch:16/51 Error_train: 0.1429876855872739 Error_test: 0.23729720131236193\n",
      "Epoch:16/51 Error_train: 0.1439256472403187 Error_test: 0.2374173763098726\n",
      "Epoch:16/51 Error_train: 0.14196170556206322 Error_test: 0.23516782508313822\n",
      "Epoch:16/51 Error_train: 0.14234933252173343 Error_test: 0.23294561781280307\n",
      "Epoch:16/51 Error_train: 0.142469527452563 Error_test: 0.23482575739308464\n",
      "Epoch:16/51 Error_train: 0.1432177477788159 Error_test: 0.240054102852033\n",
      "Epoch:16/51 Error_train: 0.14114254963381095 Error_test: 0.23451000568858998\n",
      "Epoch:16/51 Error_train: 0.14232725605679195 Error_test: 0.2415517992157696\n",
      "Epoch:16/51 Error_train: 0.1403975158241227 Error_test: 0.23846219517147024\n",
      "Epoch:16/51 Error_train: 0.14218163583985372 Error_test: 0.23265731439190696\n",
      "Epoch:16/51 Error_train: 0.14608764931468957 Error_test: 0.23769025536559407\n",
      "Epoch:16/51 Error_train: 0.1467863843381899 Error_test: 0.23684953402424844\n",
      "Epoch:16/51 Error_train: 0.14500007097849535 Error_test: 0.23815101056161747\n",
      "Epoch:16/51 Error_train: 0.1447875957271722 Error_test: 0.23849359004718906\n",
      "Epoch:16/51 Error_train: 0.1461035582527053 Error_test: 0.23857652941529342\n",
      "Epoch:16/51 Error_train: 0.1443316114882508 Error_test: 0.23587905341880075\n",
      "Epoch:16/51 Error_train: 0.1418653186873257 Error_test: 0.23536759327807583\n",
      "Epoch:16/51 Error_train: 0.14200847298691074 Error_test: 0.23368139083097206\n",
      "Epoch:16/51 Error_train: 0.1428327058652726 Error_test: 0.23530386178131957\n",
      "Epoch:16/51 Error_train: 0.14003936936597186 Error_test: 0.2323506020576373\n",
      "Epoch:16/51 Error_train: 0.138981148569907 Error_test: 0.2324967979754908\n",
      "Epoch:16/51 Error_train: 0.1385141132447529 Error_test: 0.2333438073685125\n",
      "Epoch:16/51 Error_train: 0.13838616963514064 Error_test: 0.23278082774846606\n",
      "Epoch:16/51 Error_train: 0.139701910367318 Error_test: 0.2370824333932887\n",
      "Epoch:16/51 Error_train: 0.13659878946535406 Error_test: 0.22833223684508624\n",
      "Epoch:16/51 Error_train: 0.13594657234593652 Error_test: 0.22704964256123472\n",
      "Epoch:16/51 Error_train: 0.1383286072235214 Error_test: 0.22789531645164451\n",
      "Epoch:16/51 Error_train: 0.13863305797685432 Error_test: 0.227980649160815\n",
      "Epoch:16/51 Error_train: 0.1375758801450426 Error_test: 0.22713093678508542\n",
      "Epoch:16/51 Error_train: 0.13599065214391817 Error_test: 0.2266448346284579\n",
      "Epoch:16/51 Error_train: 0.13747331221779135 Error_test: 0.2298676625066514\n",
      "Epoch:16/51 Error_train: 0.13828956144392063 Error_test: 0.2289118785011879\n",
      "Epoch:16/51 Error_train: 0.13531658775696398 Error_test: 0.22836311180408617\n",
      "Epoch:16/51 Error_train: 0.13511014437509974 Error_test: 0.22815251620154023\n",
      "Epoch:16/51 Error_train: 0.14078882122568068 Error_test: 0.2383751498828381\n",
      "Epoch:16/51 Error_train: 0.13992500929819923 Error_test: 0.23857871118226298\n",
      "Epoch:21/51 Error_train: 0.10935735468016493 Error_test: 0.21196389510796732\n",
      "Epoch:21/51 Error_train: 0.10680597781786165 Error_test: 0.2055009009900125\n",
      "Epoch:21/51 Error_train: 0.10580708689680933 Error_test: 0.20081253229570406\n",
      "Epoch:21/51 Error_train: 0.10984901115230465 Error_test: 0.20601602330768815\n",
      "Epoch:21/51 Error_train: 0.1131550527336162 Error_test: 0.21209555753395812\n",
      "Epoch:21/51 Error_train: 0.10759804313474326 Error_test: 0.20277545306294012\n",
      "Epoch:21/51 Error_train: 0.10792311583081181 Error_test: 0.20243644492566223\n",
      "Epoch:21/51 Error_train: 0.10608616995324359 Error_test: 0.1998465318620323\n",
      "Epoch:21/51 Error_train: 0.10599306627377746 Error_test: 0.20354090500425032\n",
      "Epoch:21/51 Error_train: 0.10546479156430151 Error_test: 0.2028177818264307\n",
      "Epoch:21/51 Error_train: 0.10516287378242806 Error_test: 0.20198599378418078\n",
      "Epoch:21/51 Error_train: 0.10747532232608976 Error_test: 0.2092082028241184\n",
      "Epoch:21/51 Error_train: 0.10536737825465498 Error_test: 0.20196665583815193\n",
      "Epoch:21/51 Error_train: 0.10771843828590383 Error_test: 0.20638349330532182\n",
      "Epoch:21/51 Error_train: 0.10538083538675586 Error_test: 0.20325299274049244\n",
      "Epoch:21/51 Error_train: 0.10519842982997513 Error_test: 0.1985821316937258\n",
      "Epoch:21/51 Error_train: 0.10552245313536009 Error_test: 0.1984511515450304\n",
      "Epoch:21/51 Error_train: 0.1066731271503916 Error_test: 0.1996788946699774\n",
      "Epoch:21/51 Error_train: 0.10650563798656014 Error_test: 0.20539711732469768\n",
      "Epoch:21/51 Error_train: 0.10585873951221934 Error_test: 0.20463287493753124\n",
      "Epoch:21/51 Error_train: 0.10590563660926376 Error_test: 0.2008274509098054\n",
      "Epoch:21/51 Error_train: 0.10398682668451288 Error_test: 0.19755104949488012\n",
      "Epoch:21/51 Error_train: 0.10681349163423934 Error_test: 0.19915436121497762\n",
      "Epoch:21/51 Error_train: 0.10347022244960871 Error_test: 0.1973301233211888\n",
      "Epoch:21/51 Error_train: 0.10536097366895526 Error_test: 0.20030483915853228\n",
      "Epoch:21/51 Error_train: 0.10527483934661856 Error_test: 0.20184487532643447\n",
      "Epoch:21/51 Error_train: 0.11097039695970985 Error_test: 0.20948931754757558\n",
      "Epoch:21/51 Error_train: 0.11539120302638439 Error_test: 0.2131441465908335\n",
      "Epoch:21/51 Error_train: 0.10709202658821133 Error_test: 0.2014947852101815\n",
      "Epoch:21/51 Error_train: 0.1042771567437642 Error_test: 0.19691145148458242\n",
      "Epoch:21/51 Error_train: 0.10504835903639113 Error_test: 0.20172784621127846\n",
      "Epoch:21/51 Error_train: 0.10648047826837571 Error_test: 0.2048181063650963\n",
      "Epoch:21/51 Error_train: 0.10655101314730145 Error_test: 0.20482940841264743\n",
      "Epoch:21/51 Error_train: 0.10390707692642498 Error_test: 0.20056752396417757\n",
      "Epoch:21/51 Error_train: 0.10425609737642817 Error_test: 0.1968352912922627\n",
      "Epoch:21/51 Error_train: 0.10415675292947445 Error_test: 0.1952227138415924\n",
      "Epoch:21/51 Error_train: 0.10760592032181397 Error_test: 0.19905223743002387\n",
      "Epoch:21/51 Error_train: 0.10649823743894166 Error_test: 0.19769039675196218\n",
      "Epoch:21/51 Error_train: 0.1035884635521772 Error_test: 0.19389127030959855\n",
      "Epoch:21/51 Error_train: 0.10329183357955211 Error_test: 0.19271566801563078\n",
      "Epoch:21/51 Error_train: 0.10442025017849511 Error_test: 0.19194605079875243\n",
      "Epoch:21/51 Error_train: 0.10586317452839979 Error_test: 0.19687605269530042\n",
      "Epoch:26/51 Error_train: 0.0836473253283795 Error_test: 0.1829934168624523\n",
      "Epoch:26/51 Error_train: 0.08345435080114545 Error_test: 0.18037344135931696\n",
      "Epoch:26/51 Error_train: 0.08304525127570327 Error_test: 0.17878338908904323\n",
      "Epoch:26/51 Error_train: 0.08329032283733452 Error_test: 0.17860442644123065\n",
      "Epoch:26/51 Error_train: 0.08755728306582992 Error_test: 0.182495109263283\n",
      "Epoch:26/51 Error_train: 0.08512865065495075 Error_test: 0.1810661793458367\n",
      "Epoch:26/51 Error_train: 0.08556192621750201 Error_test: 0.18564664792144936\n",
      "Epoch:26/51 Error_train: 0.08509753744873862 Error_test: 0.1869272111072445\n",
      "Epoch:26/51 Error_train: 0.08725477739576719 Error_test: 0.19399151786614516\n",
      "Epoch:26/51 Error_train: 0.0865602986356646 Error_test: 0.192413510750491\n",
      "Epoch:26/51 Error_train: 0.08408536323241589 Error_test: 0.18780005458387755\n",
      "Epoch:26/51 Error_train: 0.08928959453596876 Error_test: 0.19765754846805877\n",
      "Epoch:26/51 Error_train: 0.08875185285034212 Error_test: 0.1979214449649976\n",
      "Epoch:26/51 Error_train: 0.08661187247624876 Error_test: 0.19228077546156136\n",
      "Epoch:26/51 Error_train: 0.0860647303267744 Error_test: 0.1920856509964643\n",
      "Epoch:26/51 Error_train: 0.08533486483294511 Error_test: 0.19418191843586113\n",
      "Epoch:26/51 Error_train: 0.0832603590393197 Error_test: 0.1879410113090832\n",
      "Epoch:26/51 Error_train: 0.08337102063467226 Error_test: 0.18773809833244\n",
      "Epoch:26/51 Error_train: 0.08242260195957907 Error_test: 0.18619536577288212\n",
      "Epoch:26/51 Error_train: 0.08400588078273583 Error_test: 0.18560781019824923\n",
      "Epoch:26/51 Error_train: 0.08232585237185487 Error_test: 0.1804082234100606\n",
      "Epoch:26/51 Error_train: 0.08229804679221082 Error_test: 0.18019686875315452\n",
      "Epoch:26/51 Error_train: 0.08215518276818658 Error_test: 0.17929332345451043\n",
      "Epoch:26/51 Error_train: 0.08385174585942709 Error_test: 0.1827099380346117\n",
      "Epoch:26/51 Error_train: 0.08449729584605982 Error_test: 0.18342522089954877\n",
      "Epoch:26/51 Error_train: 0.08363230514527831 Error_test: 0.1821580296392418\n",
      "Epoch:26/51 Error_train: 0.08161856856178792 Error_test: 0.17938006033185536\n",
      "Epoch:26/51 Error_train: 0.08145046979134424 Error_test: 0.17619559901002496\n",
      "Epoch:26/51 Error_train: 0.08119438722441062 Error_test: 0.18029763774068291\n",
      "Epoch:26/51 Error_train: 0.08124417791332557 Error_test: 0.18131729724268367\n",
      "Epoch:26/51 Error_train: 0.08175113018338132 Error_test: 0.18092869265724718\n",
      "Epoch:26/51 Error_train: 0.08276829210269489 Error_test: 0.18398658685417515\n",
      "Epoch:26/51 Error_train: 0.08532679323513345 Error_test: 0.18947061607504573\n",
      "Epoch:26/51 Error_train: 0.08327046001791982 Error_test: 0.18337345740207686\n",
      "Epoch:26/51 Error_train: 0.08117257766817154 Error_test: 0.17753853659825966\n",
      "Epoch:26/51 Error_train: 0.0834120728013412 Error_test: 0.17605109169161906\n",
      "Epoch:26/51 Error_train: 0.08604435686083833 Error_test: 0.17797374851899045\n",
      "Epoch:26/51 Error_train: 0.08162672274881688 Error_test: 0.17774124201316502\n",
      "Epoch:26/51 Error_train: 0.08040420080943037 Error_test: 0.18190431439408522\n",
      "Epoch:26/51 Error_train: 0.08047952361637024 Error_test: 0.17655071231114902\n",
      "Epoch:26/51 Error_train: 0.08099207314186516 Error_test: 0.17596086742027808\n",
      "Epoch:26/51 Error_train: 0.08080142584933998 Error_test: 0.17687359905616468\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:31/51 Error_train: 0.06972852280353753 Error_test: 0.17445618181974717\n",
      "Epoch:31/51 Error_train: 0.0677326640719915 Error_test: 0.1709008155359571\n",
      "Epoch:31/51 Error_train: 0.06908001949079336 Error_test: 0.1736725811744385\n",
      "Epoch:31/51 Error_train: 0.06902091063812946 Error_test: 0.1730806318249149\n",
      "Epoch:31/51 Error_train: 0.06905746732941213 Error_test: 0.17408690047524034\n",
      "Epoch:31/51 Error_train: 0.06830535226124183 Error_test: 0.16575852724299592\n",
      "Epoch:31/51 Error_train: 0.06812948958815919 Error_test: 0.166976072354488\n",
      "Epoch:31/51 Error_train: 0.0695911396800247 Error_test: 0.1683210894614595\n",
      "Epoch:31/51 Error_train: 0.06872078613757017 Error_test: 0.16653203355813712\n",
      "Epoch:31/51 Error_train: 0.06850510477511071 Error_test: 0.16588417207229847\n",
      "Epoch:31/51 Error_train: 0.06790233726084938 Error_test: 0.16421937320632807\n",
      "Epoch:31/51 Error_train: 0.06641621329420849 Error_test: 0.16491375285752352\n",
      "Epoch:31/51 Error_train: 0.06632450712931935 Error_test: 0.16739551512825887\n",
      "Epoch:31/51 Error_train: 0.06622428108294731 Error_test: 0.16758617621099922\n",
      "Epoch:31/51 Error_train: 0.06848627669807977 Error_test: 0.1750056868062593\n",
      "Epoch:31/51 Error_train: 0.06796518759896773 Error_test: 0.17389421111094389\n",
      "Epoch:31/51 Error_train: 0.06830299638202744 Error_test: 0.17336049828695738\n",
      "Epoch:31/51 Error_train: 0.06663370298862391 Error_test: 0.16535073879017978\n",
      "Epoch:31/51 Error_train: 0.0663161229143384 Error_test: 0.16530803108997227\n",
      "Epoch:31/51 Error_train: 0.06632558336656215 Error_test: 0.17031997835663315\n",
      "Epoch:31/51 Error_train: 0.06596805950489934 Error_test: 0.17095606674113228\n",
      "Epoch:31/51 Error_train: 0.06580765605262466 Error_test: 0.16749066414379357\n",
      "Epoch:31/51 Error_train: 0.0661941146878859 Error_test: 0.1672343920595937\n",
      "Epoch:31/51 Error_train: 0.06636514299277366 Error_test: 0.1679257979057781\n",
      "Epoch:31/51 Error_train: 0.06620498695381641 Error_test: 0.16919356130350796\n",
      "Epoch:31/51 Error_train: 0.06615631361481625 Error_test: 0.1708420852458388\n",
      "Epoch:31/51 Error_train: 0.06628531854294942 Error_test: 0.17111155782475307\n",
      "Epoch:31/51 Error_train: 0.0664153093514992 Error_test: 0.17112707777338335\n",
      "Epoch:31/51 Error_train: 0.06804502194050537 Error_test: 0.1702973727031637\n",
      "Epoch:31/51 Error_train: 0.06856400060765075 Error_test: 0.1685247316882348\n",
      "Epoch:31/51 Error_train: 0.06912251187124896 Error_test: 0.16810143710432351\n",
      "Epoch:31/51 Error_train: 0.06766964492617626 Error_test: 0.1652623908385662\n",
      "Epoch:31/51 Error_train: 0.06809676555005245 Error_test: 0.1660351194002684\n",
      "Epoch:31/51 Error_train: 0.0710841287820036 Error_test: 0.16677416081428906\n",
      "Epoch:31/51 Error_train: 0.07402587177161599 Error_test: 0.17243539975758912\n",
      "Epoch:31/51 Error_train: 0.06862723139793742 Error_test: 0.17292480858225215\n",
      "Epoch:31/51 Error_train: 0.06633846262490517 Error_test: 0.17079032536866204\n",
      "Epoch:31/51 Error_train: 0.06711713353319092 Error_test: 0.1726313606389107\n",
      "Epoch:31/51 Error_train: 0.06553293824985941 Error_test: 0.17153250807417791\n",
      "Epoch:31/51 Error_train: 0.06494190937377647 Error_test: 0.1678433155847291\n",
      "Epoch:31/51 Error_train: 0.06479276395624257 Error_test: 0.17017129348593807\n",
      "Epoch:31/51 Error_train: 0.06468383320449435 Error_test: 0.16966091677322753\n",
      "Epoch:36/51 Error_train: 0.061023567298999486 Error_test: 0.1767951986577162\n",
      "Epoch:36/51 Error_train: 0.059693324811285337 Error_test: 0.17386638969525933\n",
      "Epoch:36/51 Error_train: 0.05738970156657994 Error_test: 0.16642867350435211\n",
      "Epoch:36/51 Error_train: 0.056833270580417886 Error_test: 0.158789245388961\n",
      "Epoch:36/51 Error_train: 0.05736486975684463 Error_test: 0.1581241797405613\n",
      "Epoch:36/51 Error_train: 0.05738774085183081 Error_test: 0.1581377162911498\n",
      "Epoch:36/51 Error_train: 0.05867980778647146 Error_test: 0.15686815290167963\n",
      "Epoch:36/51 Error_train: 0.06028310136548745 Error_test: 0.1590892807199465\n",
      "Epoch:36/51 Error_train: 0.05871627541356879 Error_test: 0.15923141673550348\n",
      "Epoch:36/51 Error_train: 0.058194950841210846 Error_test: 0.15844425809696944\n",
      "Epoch:36/51 Error_train: 0.0586077261854904 Error_test: 0.1590468315267128\n",
      "Epoch:36/51 Error_train: 0.0572563629141499 Error_test: 0.16009849209082966\n",
      "Epoch:36/51 Error_train: 0.05691927645054957 Error_test: 0.1604134561211866\n",
      "Epoch:36/51 Error_train: 0.05744417856449025 Error_test: 0.1663275567752678\n",
      "Epoch:36/51 Error_train: 0.05830662155742156 Error_test: 0.16703683812149347\n",
      "Epoch:36/51 Error_train: 0.05674894368221351 Error_test: 0.16200643132505488\n",
      "Epoch:36/51 Error_train: 0.0566496975143549 Error_test: 0.16523012182029195\n",
      "Epoch:36/51 Error_train: 0.05733166171588825 Error_test: 0.16442735964416733\n",
      "Epoch:36/51 Error_train: 0.05702820393350893 Error_test: 0.16386633586747104\n",
      "Epoch:36/51 Error_train: 0.057013114248423466 Error_test: 0.163894194429121\n",
      "Epoch:36/51 Error_train: 0.05696969410388797 Error_test: 0.16467732102298016\n",
      "Epoch:36/51 Error_train: 0.056997192371512906 Error_test: 0.16356984531439908\n",
      "Epoch:36/51 Error_train: 0.05755926607264263 Error_test: 0.1666479409773131\n",
      "Epoch:36/51 Error_train: 0.05754737247437423 Error_test: 0.16560690363815422\n",
      "Epoch:36/51 Error_train: 0.058161979190673715 Error_test: 0.16721111798056087\n",
      "Epoch:36/51 Error_train: 0.060653841072087704 Error_test: 0.171837656997372\n",
      "Epoch:36/51 Error_train: 0.06166338395949116 Error_test: 0.17116937011209404\n",
      "Epoch:36/51 Error_train: 0.05775425294729292 Error_test: 0.16466075655997403\n",
      "Epoch:36/51 Error_train: 0.060581573581593155 Error_test: 0.17120964670661865\n",
      "Epoch:36/51 Error_train: 0.05812164948315949 Error_test: 0.168573570755225\n",
      "Epoch:36/51 Error_train: 0.05781900097069565 Error_test: 0.16819400831172024\n",
      "Epoch:36/51 Error_train: 0.05762740240207159 Error_test: 0.1658573865863167\n",
      "Epoch:36/51 Error_train: 0.057929417663040814 Error_test: 0.1668394524135316\n",
      "Epoch:36/51 Error_train: 0.05715744103762863 Error_test: 0.1647036489212202\n",
      "Epoch:36/51 Error_train: 0.056952364133152855 Error_test: 0.1642415764084712\n",
      "Epoch:36/51 Error_train: 0.05720289348082522 Error_test: 0.16261608733473634\n",
      "Epoch:36/51 Error_train: 0.05707073224663955 Error_test: 0.15793130478104864\n",
      "Epoch:36/51 Error_train: 0.05704310467575608 Error_test: 0.15780899077143093\n",
      "Epoch:36/51 Error_train: 0.05827135689703936 Error_test: 0.15599948930549964\n",
      "Epoch:36/51 Error_train: 0.05654746450936543 Error_test: 0.15549502113267719\n",
      "Epoch:36/51 Error_train: 0.0543507042872473 Error_test: 0.16039836882320313\n",
      "Epoch:36/51 Error_train: 0.055238676418639325 Error_test: 0.1607236275912935\n",
      "Epoch:41/51 Error_train: 0.05561373064542122 Error_test: 0.17554940898718466\n",
      "Epoch:41/51 Error_train: 0.050560672189869524 Error_test: 0.1681607771906366\n",
      "Epoch:41/51 Error_train: 0.04929385089588775 Error_test: 0.16498031871395527\n",
      "Epoch:41/51 Error_train: 0.047698160176702975 Error_test: 0.16025288053298192\n",
      "Epoch:41/51 Error_train: 0.0481181065515003 Error_test: 0.16357011013135467\n",
      "Epoch:41/51 Error_train: 0.04803993519850035 Error_test: 0.161694876865634\n",
      "Epoch:41/51 Error_train: 0.04892066854404133 Error_test: 0.16220280470071136\n",
      "Epoch:41/51 Error_train: 0.04771410119296254 Error_test: 0.15835010132765243\n",
      "Epoch:41/51 Error_train: 0.046931689834355035 Error_test: 0.1550395761732129\n",
      "Epoch:41/51 Error_train: 0.04780897334109399 Error_test: 0.15131288367739346\n",
      "Epoch:41/51 Error_train: 0.047989938891846 Error_test: 0.15107959971678417\n",
      "Epoch:41/51 Error_train: 0.04968377694498448 Error_test: 0.14952528446794972\n",
      "Epoch:41/51 Error_train: 0.0498361278351375 Error_test: 0.14913833602975937\n",
      "Epoch:41/51 Error_train: 0.04988105959899948 Error_test: 0.1501043543271093\n",
      "Epoch:41/51 Error_train: 0.051831867123129274 Error_test: 0.15135818548302732\n",
      "Epoch:41/51 Error_train: 0.051140219656880884 Error_test: 0.1511579354210002\n",
      "Epoch:41/51 Error_train: 0.04958667379872909 Error_test: 0.16122818128696614\n",
      "Epoch:41/51 Error_train: 0.048241253570418675 Error_test: 0.15428458150558783\n",
      "Epoch:41/51 Error_train: 0.04885689203144753 Error_test: 0.1547777005957381\n",
      "Epoch:41/51 Error_train: 0.04742697497313071 Error_test: 0.15498863374662128\n",
      "Epoch:41/51 Error_train: 0.04771771777603087 Error_test: 0.15759536198821564\n",
      "Epoch:41/51 Error_train: 0.04776309716573064 Error_test: 0.15511348409677073\n",
      "Epoch:41/51 Error_train: 0.04739524375707171 Error_test: 0.15698364428421016\n",
      "Epoch:41/51 Error_train: 0.04677685972181799 Error_test: 0.1561611273895122\n",
      "Epoch:41/51 Error_train: 0.04607577240880933 Error_test: 0.15417295719355587\n",
      "Epoch:41/51 Error_train: 0.04583179173951474 Error_test: 0.15262801026610853\n",
      "Epoch:41/51 Error_train: 0.04962046725290074 Error_test: 0.16442781827895955\n",
      "Epoch:41/51 Error_train: 0.048532821533378206 Error_test: 0.1637077004901103\n",
      "Epoch:41/51 Error_train: 0.04707611336113414 Error_test: 0.1602405717305149\n",
      "Epoch:41/51 Error_train: 0.048003168645447854 Error_test: 0.1586045173453059\n",
      "Epoch:41/51 Error_train: 0.048219417992895176 Error_test: 0.15629605887206663\n",
      "Epoch:41/51 Error_train: 0.04635594705219311 Error_test: 0.15503217878084496\n",
      "Epoch:41/51 Error_train: 0.046507452769261985 Error_test: 0.1531151805309929\n",
      "Epoch:41/51 Error_train: 0.046304567763433196 Error_test: 0.1527779301976534\n",
      "Epoch:41/51 Error_train: 0.04638078759486651 Error_test: 0.15121919500512512\n",
      "Epoch:41/51 Error_train: 0.04671177977645467 Error_test: 0.15343742771702804\n",
      "Epoch:41/51 Error_train: 0.04703145248564129 Error_test: 0.15255702703764648\n",
      "Epoch:41/51 Error_train: 0.047220135920946024 Error_test: 0.1516934849492922\n",
      "Epoch:41/51 Error_train: 0.04740194225591829 Error_test: 0.15863430155056554\n",
      "Epoch:41/51 Error_train: 0.04722685152452067 Error_test: 0.1591516191467694\n",
      "Epoch:41/51 Error_train: 0.047356325021634144 Error_test: 0.16269742506099852\n",
      "Epoch:41/51 Error_train: 0.046162839758518086 Error_test: 0.16088235895904718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:46/51 Error_train: 0.043580916459584396 Error_test: 0.15885524040175103\n",
      "Epoch:46/51 Error_train: 0.04338678082616609 Error_test: 0.1670328978885142\n",
      "Epoch:46/51 Error_train: 0.04350366860379178 Error_test: 0.16844318181497114\n",
      "Epoch:46/51 Error_train: 0.04242684071264099 Error_test: 0.16631621856266657\n",
      "Epoch:46/51 Error_train: 0.04196467082654085 Error_test: 0.16480253279260998\n",
      "Epoch:46/51 Error_train: 0.04025661035793676 Error_test: 0.1578603119541279\n",
      "Epoch:46/51 Error_train: 0.04046204731456474 Error_test: 0.15315441607385474\n",
      "Epoch:46/51 Error_train: 0.042084069624420656 Error_test: 0.1604112228578482\n",
      "Epoch:46/51 Error_train: 0.04047452661954239 Error_test: 0.1572943527301521\n",
      "Epoch:46/51 Error_train: 0.039897290380602184 Error_test: 0.15503727334851292\n",
      "Epoch:46/51 Error_train: 0.04000945502971825 Error_test: 0.1543292926638313\n",
      "Epoch:46/51 Error_train: 0.039698732530092186 Error_test: 0.15261586621670795\n",
      "Epoch:46/51 Error_train: 0.039880705715223466 Error_test: 0.1532081694622039\n",
      "Epoch:46/51 Error_train: 0.039960605155277835 Error_test: 0.15294277370659873\n",
      "Epoch:46/51 Error_train: 0.0393452023478027 Error_test: 0.15429669123004316\n",
      "Epoch:46/51 Error_train: 0.044003791310306115 Error_test: 0.1648403861694001\n",
      "Epoch:46/51 Error_train: 0.043425826636060226 Error_test: 0.16346539894206985\n",
      "Epoch:46/51 Error_train: 0.041004733735347125 Error_test: 0.15841038050032252\n",
      "Epoch:46/51 Error_train: 0.039749039626035654 Error_test: 0.1552672527439565\n",
      "Epoch:46/51 Error_train: 0.040495070472713224 Error_test: 0.158036748850286\n",
      "Epoch:46/51 Error_train: 0.04015880377553872 Error_test: 0.15655374888644974\n",
      "Epoch:46/51 Error_train: 0.039065499936094684 Error_test: 0.15305757806984957\n",
      "Epoch:46/51 Error_train: 0.03942135590601191 Error_test: 0.15356334843344976\n",
      "Epoch:46/51 Error_train: 0.03908062620465486 Error_test: 0.15217658301938708\n",
      "Epoch:46/51 Error_train: 0.039039096854238516 Error_test: 0.15205689530648261\n",
      "Epoch:46/51 Error_train: 0.03909818624173222 Error_test: 0.15071350096754302\n",
      "Epoch:46/51 Error_train: 0.03974876032038137 Error_test: 0.15167698740533198\n",
      "Epoch:46/51 Error_train: 0.04018859118939781 Error_test: 0.1506006935746228\n",
      "Epoch:46/51 Error_train: 0.040485991507952894 Error_test: 0.1505484132545241\n",
      "Epoch:46/51 Error_train: 0.03921219067746299 Error_test: 0.15302535579055465\n",
      "Epoch:46/51 Error_train: 0.038633904520087775 Error_test: 0.15296165561744232\n",
      "Epoch:46/51 Error_train: 0.03930681721413662 Error_test: 0.15239222699818444\n",
      "Epoch:46/51 Error_train: 0.03909623018064671 Error_test: 0.15295391016669108\n",
      "Epoch:46/51 Error_train: 0.03983650163084359 Error_test: 0.15208664417232454\n",
      "Epoch:46/51 Error_train: 0.03878998195480093 Error_test: 0.1503123595743218\n",
      "Epoch:46/51 Error_train: 0.038933307967349326 Error_test: 0.149681403643234\n",
      "Epoch:46/51 Error_train: 0.038965332843969955 Error_test: 0.1498214354421799\n",
      "Epoch:46/51 Error_train: 0.04004593981714855 Error_test: 0.15343218639298212\n",
      "Epoch:46/51 Error_train: 0.039454176789182234 Error_test: 0.15529890435108162\n",
      "Epoch:46/51 Error_train: 0.04000246600400944 Error_test: 0.15707388763202543\n",
      "Epoch:46/51 Error_train: 0.039889498447086516 Error_test: 0.15340861792377747\n",
      "Epoch:46/51 Error_train: 0.0386884538920482 Error_test: 0.1501300411478473\n",
      "Epoch:51/51 Error_train: 0.0345968933865213 Error_test: 0.15279546964563612\n",
      "Epoch:51/51 Error_train: 0.034006651070833324 Error_test: 0.15207110231118107\n",
      "Epoch:51/51 Error_train: 0.034033460889734135 Error_test: 0.1502696307651186\n",
      "Epoch:51/51 Error_train: 0.03436681114654097 Error_test: 0.14849472343652695\n",
      "Epoch:51/51 Error_train: 0.03531835421058328 Error_test: 0.15099071800570582\n",
      "Epoch:51/51 Error_train: 0.03520027295283046 Error_test: 0.15000738773331906\n",
      "Epoch:51/51 Error_train: 0.03506498744332394 Error_test: 0.1490047330818546\n",
      "Epoch:51/51 Error_train: 0.03504523815505064 Error_test: 0.15265003045531741\n",
      "Epoch:51/51 Error_train: 0.03530487938505712 Error_test: 0.14919752592657995\n",
      "Epoch:51/51 Error_train: 0.036739339888615226 Error_test: 0.14939772885835984\n",
      "Epoch:51/51 Error_train: 0.03565717460846521 Error_test: 0.1483382966356095\n",
      "Epoch:51/51 Error_train: 0.03567648461990185 Error_test: 0.14820112637108868\n",
      "Epoch:51/51 Error_train: 0.03758791480490457 Error_test: 0.15304114555464488\n",
      "Epoch:51/51 Error_train: 0.03713980217788148 Error_test: 0.15188033131229714\n",
      "Epoch:51/51 Error_train: 0.03603053934623971 Error_test: 0.1520065187418588\n",
      "Epoch:51/51 Error_train: 0.03655472428874351 Error_test: 0.15183869870979985\n",
      "Epoch:51/51 Error_train: 0.03653045525511169 Error_test: 0.1525484770168528\n",
      "Epoch:51/51 Error_train: 0.035813546032371385 Error_test: 0.1514229251161766\n",
      "Epoch:51/51 Error_train: 0.03533595833638324 Error_test: 0.1508847913127093\n",
      "Epoch:51/51 Error_train: 0.03548903843803561 Error_test: 0.15091139610843657\n",
      "Epoch:51/51 Error_train: 0.03506102699975548 Error_test: 0.1537567172153279\n",
      "Epoch:51/51 Error_train: 0.03526416296336835 Error_test: 0.15676241360680254\n",
      "Epoch:51/51 Error_train: 0.03551035004034181 Error_test: 0.15686759543062578\n",
      "Epoch:51/51 Error_train: 0.034179937750035284 Error_test: 0.15202806851478975\n",
      "Epoch:51/51 Error_train: 0.034084074263842266 Error_test: 0.15059993661100618\n",
      "Epoch:51/51 Error_train: 0.03495815361860712 Error_test: 0.154657110307151\n",
      "Epoch:51/51 Error_train: 0.03495551493975035 Error_test: 0.15465525533766128\n",
      "Epoch:51/51 Error_train: 0.03536638762411814 Error_test: 0.15546979696254354\n",
      "Epoch:51/51 Error_train: 0.037195076895788215 Error_test: 0.15074125402223382\n",
      "Epoch:51/51 Error_train: 0.03663331696306433 Error_test: 0.1515905925155401\n",
      "Epoch:51/51 Error_train: 0.03808535563402063 Error_test: 0.15836530214856182\n",
      "Epoch:51/51 Error_train: 0.03599490750199559 Error_test: 0.15560810596704241\n",
      "Epoch:51/51 Error_train: 0.034632295174984104 Error_test: 0.15353562827822975\n",
      "Epoch:51/51 Error_train: 0.03350965494766018 Error_test: 0.14940118970253408\n",
      "Epoch:51/51 Error_train: 0.03347347416812665 Error_test: 0.14906517102518382\n",
      "Epoch:51/51 Error_train: 0.037132936960187976 Error_test: 0.16111954328245642\n",
      "Epoch:51/51 Error_train: 0.03446522474093883 Error_test: 0.1478491347246792\n",
      "Epoch:51/51 Error_train: 0.03472134851047888 Error_test: 0.14707782575107622\n",
      "Epoch:51/51 Error_train: 0.03465983739759235 Error_test: 0.147137185187505\n",
      "Epoch:51/51 Error_train: 0.03414014075493982 Error_test: 0.14731547091416566\n",
      "Epoch:51/51 Error_train: 0.03398251037464618 Error_test: 0.1474728806413226\n",
      "Epoch:51/51 Error_train: 0.03361236633851596 Error_test: 0.14956182779184185\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc_train: 99.4060876020787% Acc_test: 96.44444444444444%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "img_size = 8    # 이미지 크기와 폭\n",
    "n_mid = 16      # 은닉층 뉴런 수\n",
    "n_out = 10\n",
    "eta = 0.001     # 학습률\n",
    "epochs = 51\n",
    "batch_size = 32\n",
    "interval = 5    # 경과 시간 표시 간격\n",
    "\n",
    "digits_data = datasets.load_digits()\n",
    "\n",
    "input_data = np.asarray(digits_data.data)\n",
    "input_data = (input_data - np.average(input_data)) / np.std(input_data)\n",
    "\n",
    "correct = np.asarray(digits_data.target)\n",
    "correct_data = np.zeros((len(correct), n_out))\n",
    "for i in range(len(correct)):\n",
    "    correct_data[i, correct[i]] = 1   # 원핫 인코딩\n",
    "    \n",
    "# 데이터 분할\n",
    "x_train, x_test, t_train, t_test = train_test_split(input_data, correct_data)\n",
    "\n",
    "# 전결합층의 부모 클래스\n",
    "class BaseLayer:\n",
    "    def update(self, eta):\n",
    "        self.w -= eta * self.grad_w\n",
    "        self.b -= eta * self.grad_b\n",
    "        \n",
    "# 은닉층\n",
    "class MiddleLayer(BaseLayer):\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) * np.sqrt(2/n_upper)\n",
    "        self.b = np.zeros(n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        self.u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.where(self.u <= 0, 0, self.u)   # ReLU\n",
    "        \n",
    "    def backward(self, grad_y):\n",
    "        delta = grad_y * np.where(self.u <= 0, 0, 1)  # ReLU 미분\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        self.grad_x = np.dot(delta, self.w.T)\n",
    "        \n",
    "# 출력층\n",
    "class OutputLayer(BaseLayer):\n",
    "    def __init__(self, n_upper, n):\n",
    "        self.w = np.random.randn(n_upper, n) / np.sqrt(n_upper)    #자비에르 초기화 기반의 초깃값\n",
    "        self.b = np.zeros(n)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        u = np.dot(x, self.w) + self.b\n",
    "        self.y = np.exp(u)/np.sum(np.exp(u), axis=1, keepdims=True)\n",
    "        \n",
    "    def backward(self, t):\n",
    "        delta = self.y - t\n",
    "        \n",
    "        self.grad_w = np.dot(self.x.T, delta)\n",
    "        self.grad_b = np.sum(delta, axis=0)\n",
    "        self.grad_x = np.dot(delta, self.w.T)\n",
    "        \n",
    "# 각 층의 초기화\n",
    "layers = [MiddleLayer(img_size*img_size, n_mid),\n",
    "         MiddleLayer(n_mid, n_mid),\n",
    "         OutputLayer(n_mid, n_out)]\n",
    "\n",
    "# 순전파\n",
    "def forward_propagation(x):\n",
    "    for layer in layers:\n",
    "        layer.forward(x)\n",
    "        x = layer.y\n",
    "    return x\n",
    "\n",
    "# 역전파\n",
    "def backwardpropagation(t):\n",
    "    grad_y = t\n",
    "    for layer in reversed(layers):\n",
    "        layer.backward(grad_y)\n",
    "        grad_y = layer.grad_x\n",
    "    return grad_y\n",
    "\n",
    "# 파라미터 갱신\n",
    "def update_params():\n",
    "    for layer in layers:\n",
    "        layer.update(eta)\n",
    "        \n",
    "# 오차 측정\n",
    "def get_error(x,t):\n",
    "    y = forward_propagation(x)\n",
    "    return -np.sum(t*np.log(y+1e-7)) / len(y)   # 교차 엔트로피 오차\n",
    "\n",
    "# 정답률 측정\n",
    "def get_accuracy(x, t):\n",
    "    y = forward_propagation(x)\n",
    "    count = np.sum(np.argmax(y, axis=1) == np.argmax(t, axis=1))\n",
    "    return count / len(y)\n",
    "\n",
    "# 오차 기록\n",
    "error_record_train = []\n",
    "error_record_test = []\n",
    "\n",
    "n_batch = len(x_train) // batch_size   # 1에포크당 배치 개수\n",
    "for i in range(epochs):\n",
    "    \n",
    "    index_random = np.arange(len(x_train))\n",
    "    np.random.shuffle(index_random)\n",
    "    for j in range(n_batch):\n",
    "        \n",
    "        # 미니 배치 생성\n",
    "        mb_index = index_random[j*batch_size : (j+1)*batch_size]\n",
    "        x_mb = x_train[mb_index, :]\n",
    "        t_mb = t_train[mb_index, :]\n",
    "        \n",
    "        # 순전파와 역전파\n",
    "        forward_propagation(x_mb)\n",
    "        backwardpropagation(t_mb)\n",
    "        \n",
    "        # 파라미터 갱신\n",
    "        update_params()\n",
    "        \n",
    "        # 오차 측정 및 기록\n",
    "        error_train = get_error(x_train, t_train)\n",
    "        error_record_train.append(error_train)\n",
    "        error_test = get_error(x_test, t_test)\n",
    "        error_record_test.append(error_test)\n",
    "        \n",
    "        # 경과 표시\n",
    "        if i%interval == 0 :\n",
    "            print(\"Epoch:\" + str(i+1) + \"/\" + str(epochs), \n",
    "                  \"Error_train: \" + str(error_train),\n",
    "                  \"Error_test: \" + str(error_test))\n",
    "            \n",
    "# 오차 추이를 그래프로 표시\n",
    "plt.plot(range(1, len(error_record_train)+1), error_record_train, label=\"Train\")\n",
    "plt.plot(range(1, len(error_record_test)+1), error_record_test, label=\"Test\")\n",
    "plt.legend()\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.show()\n",
    "\n",
    "# 정답률 측정\n",
    "acc_train = get_accuracy(x_train, t_train)\n",
    "acc_test = get_accuracy(x_test, t_test)\n",
    "print(\"Acc_train: \"+str(acc_train*100)+\"%\",\n",
    "     \"Acc_test: \"+str(acc_test*100)+\"%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
